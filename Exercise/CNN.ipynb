{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import autograd,init,nd,gluon\n",
    "import d2lzh as d2l\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from mxnet.gluon import nn,data as gdata,loss as gloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Conv2D(channels=6,kernel_size=5,activation='sigmoid'),\n",
    "        nn.MaxPool2D(pool_size=2,strides=2),\n",
    "        nn.Conv2D(channels=16,kernel_size=5,activation='sigmoid'),\n",
    "        nn.MaxPool2D(pool_size=2,strides=2),\n",
    "        \n",
    "        nn.Dense(120,activation='sigmoid'),\n",
    "        nn.Dense(84,activation='sigmoid'),\n",
    "        nn.Dense(10)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv0 output shape:\t (1, 6, 24, 24)\n",
      "pool0 output shape:\t (1, 6, 12, 12)\n",
      "conv1 output shape:\t (1, 16, 8, 8)\n",
      "pool1 output shape:\t (1, 16, 4, 4)\n",
      "dense0 output shape:\t (1, 120)\n",
      "dense1 output shape:\t (1, 84)\n",
      "dense2 output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = nd.random.uniform(shape=(1,1,28,28))\n",
    "net.initialize(force_reinit=True)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.name,\"output shape:\\t\",X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取数据和训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on gpu(0)\n",
      "epoch 1, loss 2.3201, train acc 0.100, test acc 0.100, time 6.3 sec\n",
      "epoch 2, loss 1.9582, train acc 0.248, test acc 0.559, time 6.8 sec\n",
      "epoch 3, loss 0.9691, train acc 0.617, test acc 0.682, time 9.0 sec\n",
      "epoch 4, loss 0.7613, train acc 0.704, test acc 0.732, time 6.6 sec\n",
      "epoch 5, loss 0.6685, train acc 0.735, test acc 0.756, time 7.6 sec\n"
     ]
    }
   ],
   "source": [
    "lr,num_epochs = 0.9,5\n",
    "batch_size = 256\n",
    "ctx = d2l.try_gpu()\n",
    "train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "net.initialize(force_reinit=True,ctx=ctx,init=init.Xavier())\n",
    "trainer = gluon.Trainer(net.collect_params(),'sgd',{'learning_rate':lr})\n",
    "d2l.train_ch5(net,train_iter,test_iter,batch_size,trainer,ctx,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch5(net,train_iter,test_iter,batch_size,trainer,ctx,num):\n",
    "    print(\"training on \",ctx)\n",
    "    loss = gloss.SoftmaxCELoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum,train_acc_sum,n,start = 0.0,0.0,0,time.time()\n",
    "        for X,y in train_iter:\n",
    "            X,y = X.as_in_context(ctx),y.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                y_hat = net(X)\n",
    "                l = loss(y_hat,y).sum()\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            y = y.astype('float32')\n",
    "            train_l_sum += l.asscalar()\n",
    "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n",
    "            n += y.size\n",
    "        test_acc = evaluate_accuracy(test_iter,net,ctx)\n",
    "        print('epoch %d, loss %.4f, train_acc %.3f, test acc %.3f, time %.1f sec'\n",
    "                 % (epoch+1,train_l_sum/n,train_acc_sum/n,test_acc,time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr,num_epochs =0.9,5\n",
    "net.initialize(force_reinit=True,ctx=ctx,init=init.Xavier())\n",
    "trainer = gluon.Trainer(net.collect_params(),'sgd',{'learning_rate':lr})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show():\n",
    "    for X,y in test_iter:\n",
    "        break\n",
    "    true_labels = d2l.get_fashion_mnist_labels(y.asnumpy())\n",
    "    pred_labels = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1).asnumpy())\n",
    "    titles = [true + '\\n' + pred for true, pred in zip(true_labels, pred_labels)]\n",
    "    d2l.show_fashion_mnist(X[0:9], titles[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用GPU训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on gpu(0)\n",
      "epoch 1, loss 1.1577, train acc 0.546, test acc 0.687, time 7.1 sec\n",
      "epoch 2, loss 0.7997, train acc 0.691, test acc 0.731, time 7.2 sec\n",
      "epoch 3, loss 0.6730, train acc 0.735, test acc 0.748, time 7.2 sec\n",
      "epoch 4, loss 0.6215, train acc 0.756, test acc 0.779, time 7.9 sec\n",
      "epoch 5, loss 0.5778, train acc 0.774, test acc 0.790, time 7.5 sec\n"
     ]
    }
   ],
   "source": [
    "d2l.train_ch5(net,train_iter,test_iter,batch_size,trainer,ctx,num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
