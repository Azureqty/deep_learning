# 从完全连接的层到卷积
:label:`sec_why-conv`

迄今为止，在我们处理表格数据时，我们迄今讨论的模型仍然是适当的选择。通过表格，我们的意思是数据由与要素对应的示例和列对应的行组成。对于表格数据，我们可能会预计我们所寻求的模式可能涉及要素之间的交互，但我们并不假定任何关于要素交互方式的结构 * 优先级 *。

有时候，我们确实缺乏指导精巧建筑的建设的知识。在这些情况下，MLP 可能是我们所能做的最好的。然而，对于高维感知数据，这种无结构的网络可能会变得笨拙。

例如，让我们回到我们区分猫和狗的运行例子。假设我们做一个彻底的工作，在数据收集，收集一百万像素照片的注释数据集。这意味着网络的每个输入都有一百万个维度。即使大幅缩小到千个隐藏尺寸，也需要一个以 $10^6 \times 10^3 = 10^9$ 参数为特征的完全连接层。除非我们拥有大量的 GPU、分布式优化的天赋以及极大的耐心，否则学习这个网络的参数可能会被证明是不可行的。

仔细的读者可能会反对这一论点，理由是可能不需要一百万像素的分辨率。然而，虽然我们可能能够摆脱十万像素，但我们隐藏的大小为 1000 的图层严重低估了学习图像的良好表示所需的隐藏单位的数量，因此一个实用的系统仍然需要数十亿个参数。此外，通过拟合如此多的参数来学习分类器可能需要收集巨大的数据集。然而今天无论是人类和计算机都能够区分猫从狗相当好，看似矛盾这些直觉。这是因为图像展现出丰富的结构，可以被人类和机器学习模型所利用。卷积神经网络 (CNN) 是机器学习利用自然图像中某些已知结构而采用的一种创造性方式。

## 不变性

想象一下，您想要检测图像中的对象。似乎合理的是，无论我们用来识别对象的方法都不应过分关心图像中物体的确切位置。理想情况下，我们的系统应该利用这些知识。猪通常不飞，飞机通常不会游泳。尽管如此，我们仍然应该认识到一只猪是一个出现在图像的顶部。我们可以从儿童游戏 “沃尔多在哪里”（在 :numref:`img_waldo` 中描述）中汲取一些灵感。游戏包括一些混乱的场景与活动爆裂.沃尔多出现在每个地方，通常潜伏在一些不太可能的位置。读者的目标是找到他。尽管他的特色装备，这可能是令人惊讶的困难，由于大量的分心。但是，* 沃尔多看起来像 * 并不取决于沃尔多的位置 *。我们可以使用 Waldo 检测器扫描图像，该检测器可以为每个贴片分配一个分数，指示贴片包含 Waldo 的可能性。CNN 系统化了这个 * 空间不变性 * 的概念，利用它来学习具有较少参数的有用表示。

![An image of the "Where's Waldo" game.](../img/where-wally-walker-books.jpg)
:width:`400px`
:label:`img_waldo`

我们现在可以通过列举几个 desiderata 来指导我们设计适用于计算机视觉的神经网络架构，使这些直觉更具体：

1. 在最早的图层中，我们的网络应该对相同的补丁作出类似的响应，而不管它在图像中显示的位置。这个原则被称为 * 翻译不变 *。
1. 网络的最早图层应该集中于局部区域，而不考虑遥远区域中的图像内容。这是 * 本地 * 原则。最终，可以聚合这些局部制图表达，以便在整个影像级别进行预测。

让我们看看这是如何转化为数学。

## 约束 MLP

首先，我们可以考虑一个带有二维图像 $\mathbf{X}$ 的 MLP 作为输入，其直接隐藏表示 $\mathbf{H}$ 类似地表示为数学矩阵和代码中的二维张量，其中 $\mathbf{X}$ 和 $\mathbf{H}$ 具有相同的形状。让那个沉进去我们现在不仅将输入设想为具有空间结构的隐藏表示。

让 $[\mathbf{X}]_{i, j}$ 和 $[\mathbf{H}]_{i, j}$ 分别表示输入图像和隐藏表示中位于位置的像素（$i$，$j$）。因此，为了让每个隐藏单位接收来自每个输入像素的输入，我们将从使用权重矩阵（正如我们之前在 MLP 中所做的那样）切换到将我们的参数表示为四阶权重张量 $\mathsf{W}$。假设 $\mathbf{U}$ 包含偏差，我们可以正式将完全连接的图层表示为

$$\begin{aligned} \left[\mathbf{H}\right]_{i, j} &= [\mathbf{U}]_{i, j} + \sum_k \sum_l[\mathsf{W}]_{i, j, k, l}  [\mathbf{X}]_{k, l}\\ &=  [\mathbf{U}]_{i, j} +
\sum_a \sum_b [\mathsf{V}]_{i, j, a, b}  [\mathbf{X}]_{i+a, j+b}.\end{aligned},$$

其中从 $\mathsf{W}$ 到 $\mathsf{V}$ 的开关现在完全是表面的，因为两个四阶张量中的系数之间存在一对一的对应关系。我们只需重新指数下标 $(k, l)$，即可获得 $k = i+a$ 和 $l = j+b$。换句话说，我们设置了 $[\mathsf{V}]_{i, j, a, b} = [\mathsf{W}]_{i, j, i+a, j+b}$。指数 $a$ 和 $b$ 在正负两方面运行，覆盖了整个图像。对于隐藏表示 $[\mathbf{H}]_{i, j}$ 中的任何给定位置（$i$，$j$），我们通过对 $x$ 中的像素进行求和来计算其值，以 $(i, j)$ 为中心并加权为 $[\mathsf{V}]_{i, j, a, b}$。

### 翻译不变

现在让我们援引上面确立的第一个原则：翻译不变性。这意味着输入 $\mathbf{X}$ 的转移应该只会导致隐藏表示 $\mathbf{H}$ 的转变。这只有在 $\mathsf{V}$ 和 $\mathbf{U}$ 实际上并不依赖于 $\mathbf{U}$ 的情况下才可能实现，也就是说，我们有 $[\mathsf{V}]_{i, j, a, b} = [\mathbf{V}]_{a, b}$ 和 $\mathbf{U}$ 是一个常数，比如说 $u$。因此，我们可以简化 $\mathbf{H}$ 的定义：

$$[\mathbf{H}]_{i, j} = u + \sum_a\sum_b [\mathbf{V}]_{a, b}  [\mathbf{X}]_{i+a, j+b}.$$

这是一个 * 卷曲 *！我们正在对位置 $(i, j)$ 附近的像素进行有效的权重，系数为 $[\mathbf{V}]_{a, b}$，以获得值 $[\mathbf{H}]_{i, j}$。请注意，$[\mathbf{V}]_{a, b}$ 所需的系数比 $[\mathsf{V}]_{i, j, a, b}$ 少得多，因为它不再依赖于图像中的位置。我们取得了重大进展！

###  地方地

现在让我们援引第二个原则：地域性。如上所述，我们认为，我们不应该远离 $(i, j)$ 位置，以便收集相关信息来评估 $[\mathbf{H}]_{i, j}$ 发生的情况。这意味着在某个范围之外，我们应该设置 $|a|> \Delta$ 或 $|b| > \Delta$ 的范围之外。同样地，我们可以将 $[\mathbf{H}]_{i, j}$ 重写为

$$[\mathbf{H}]_{i, j} = u + \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} [\mathbf{V}]_{a, b}  [\mathbf{X}]_{i+a, j+b}.$$
:eqlabel:`eq_conv-layer`

请注意，简而言之，:eqref:`eq_conv-layer` 是一个 * 卷积层 *。
*卷积神经网络 * (CNN)
是一个包含卷积层的特殊神经网络家族。在深度学习研究社区中，$\mathbf{V}$ 被称为 * 卷积内核 *、* 过滤器 * 或仅称为图层的 * 权重 *，这些参数通常是可学习的参数。当局部区域较小时，与完全连接的网络相比，差异可能很大。虽然以前，我们可能需要数十亿个参数来表示图像处理网络中的单个图层，但我们现在通常只需要几百个参数，而不会改变输入或隐藏制图表达的维度。为参数大幅减少付出的代价是，我们的特征现在是翻译不变的，我们的图层只能包含本地信息，当确定每个隐藏激活的价值时。所有的学习都取决于强加感应偏见。当这种偏差与现实一致时，我们得到了可以很好地概括到看不见的数据的样本效率模型。但是，当然，如果这些偏见与现实不一致，例如，如果图像不是翻译不变的，那么我们的模型可能会很难拟合我们的训练数据。

## 卷积

在进一步研究之前，我们应该简要回顾为什么上述操作被称为卷积。在数学中，两个函数之间的 * 卷积 *，比如说 $f, g: \mathbb{R}^d \to \mathbb{R}$ 被定义为

$$(f * g)(\mathbf{x}) = \int f(\mathbf{z}) g(\mathbf{x}-\mathbf{z}) d\mathbf{z}.$$

也就是说，当一个函数被 “翻转” 并移动 $\mathbf{x}$ 时，我们测量 $f$ 和 $g$ 之间的重叠。每当我们有离散的对象时，积分就会变成一个总和。例如，对于索引运行超过 $\mathbb{Z}$ 的方形和无限维向量集合中的向量，我们得到以下定义：

$$(f * g)(i) = \sum_a f(a) g(i-a).$$

对于二维张量，我们有一个相应的总和，分别为 $f$ 和 $(i-a, j-b)$ 的指数：

$$(f * g)(i, j) = \sum_a\sum_b f(a, b) g(i-a, j-b).$$
:eqlabel:`eq_2d-conv-discrete`

这看起来类似于 :eqref:`eq_conv-layer`，有一个主要区别。我们不是使用 $(i+a, j+b)$，而是使用差异。但请注意，这种区别主要是表面性的，因为我们总是可以匹配 :eqref:`eq_conv-layer` 和 :eqref:`eq_2d-conv-discrete` 之间的符号。我们在 :eqref:`eq_conv-layer` 中的原始定义更正确地描述了 * 交叉关联 *。我们将在下一节中再次讨论这一问题。

## “沃尔多在哪里” 回顾

回到我们的 Waldo 探测器，让我们看看这是什么样子。卷积层根据滤波器 $\mathsf{V}$ 选取给定大小的窗口，并对强度进行称重，如 :numref:`fig_waldo_mask` 所示。我们可能旨在学习一个模型，以便在 “华尔顿” 最高的位置，我们应该在隐藏图层表示中找到一个峰值。

![Detect Waldo.](../img/waldo-mask.jpg)
:width:`400px`
:label:`fig_waldo_mask`

### 渠道
:label:`subsec_why-conv-channels`

这种方法只有一个问题。到目前为止，我们幸福地忽略了图像由 3 个通道组成：红色、绿色和蓝色。实际上，图像不是二维物体，而是三阶张量，其特点是高度、宽度和通道，例如形状为 $1024 \times 1024 \times 3$ 像素。虽然前两个轴涉及空间关系，但第三个轴可视为为每个像素位置分配多维制图表达。因此，我们的指数为 $\mathsf{X}$。卷积滤波器必须相应地适应。我们现在已经拥有了 $[\mathsf{V}]_{a,b,c}$，而不是 $[\mathbf{V}]_{a,b}$。

此外，正如我们的输入由三阶张量组成一样，最好将我们的隐藏表示类似于三阶张量 $\mathsf{H}$。换句话说，我们不仅需要对应于每个空间位置的单个隐藏制图表达，而是需要一个与每个空间位置相对应的整个隐藏制图表达矢量。我们可以认为隐藏的表示是由一些堆叠在彼此之上的二维网格组成的。与输入一样，这些通道有时称为 * 频道 *。它们有时也称为 * 要素地图 *，因为每个图层都为后续图层提供了一组空间化的学习要素。直观而言，您可能会想象在较接近输入的较低图层中，某些通道可能会专门识别边缘，而其他通道则可以识别纹理。

为了在输入 ($\mathsf{X}$) 和隐藏表示 ($\mathsf{H}$) 中支持多个通道，我们可以将第四个坐标添加到 $\mathsf{V}$：$[\mathsf{V}]_{a, b, c, d}$。把我们所拥有的一切放在一起：

$$[\mathsf{H}]_{i,j,d} = \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} \sum_c [\mathsf{V}]_{a, b, c, d} [\mathsf{X}]_{i+a, j+b, c},$$
:eqlabel:`eq_conv-layer-channels`

其中 $d$ 在隐藏的表示中对输出通道进行索引。随后的卷积层将继续采用三阶张量 $\mathsf{H}$ 作为输入。更一般地说，:eqref:`eq_conv-layer-channels` 是多个通道的卷积层的定义，其中 $\mathsf{V}$ 是层的内核或滤波器。

我们仍然需要处理许多行动。例如，我们需要弄清楚如何将所有隐藏的表示组合到单个输出中，例如，图像中是否有 Waldo * 在任何位置。我们还需要决定如何高效地计算事物，如何组合多层、适当的激活函数，以及如何做出合理的设计选择，以便产生实际上有效的网络。我们将在本章其余部分讨论这些问题。

## 摘要

* 图像中的翻译不变性意味着将以相同的方式处理图像的所有补丁。
* 局部性意味着只使用一小部分像素邻域来计算相应的隐藏制图表达。
* 在图像处理中，卷积图层所需的参数通常比完全连接的图层少得多。
* CNN 是一个特殊的神经网络系列，其中包含卷积层。
* 输入和输出通道允许我们的模型在每个空间位置捕捉图像的多个方面。

## 练习

1. 假定卷积内核的大小为 $\Delta = 0$。表明在这种情况下，卷积内核为每组通道独立实现 MLP。
1. 为什么翻译不变性毕竟不是一个好主意？
1. 在决定如何处理与图像边界上像素位置相对应的隐藏表示时，我们必须处理哪些问题？
1. 描述音频的类似卷积层。
1. 您是否认为卷积图层也可能适用于文本数据？为什么还是为什么不呢？
1. 证明那是什么

[Discussions](https://discuss.d2l.ai/t/64)
