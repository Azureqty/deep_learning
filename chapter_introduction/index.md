# 介绍
:label:`chap_introduction`

直到最近，几乎每个我们每天互动的计算机程序都是由软件开发人员从第一个原则编码的。假设我们想编写一个应用程序来管理电子商务平台。在对白板进行了几个小时的思考之后，我们会想出一个可行的解决方案的广泛描述，可能看起来像这样：(i) 用户通过在 Web 浏览器或移动应用程序中运行的界面与应用程序进行交互；(ii) 我们的应用程序与商业级数据库引擎进行交互，以跟踪每个用户的状态并维护历史交易记录；(iii) 在我们应用程序的核心，我们应用程序的 * 业务逻辑 *（你可能会说，* 脑 *）详细说明了我们的计划应采取在每一种可以想象的情况下。

为了构建应用程序的 * 大脑 *，我们必须逐步了解我们预计遇到的每一个可能的角落案例，并制定适当的规则。每当买家单击将商品添加到购物车时，我们都会向购物车数据库表中添加一个条目，将该用户的 ID 与请求产品的 ID 关联起来。虽然很少有开发人员第一次完全正确（可能需要一些测试才能解决问题），但在大多数情况下，我们可以从第一个原则编写这样的程序，并自信地启动它 * 之前看到真正的客户 *。我们能够根据第一个原则设计自动化系统，通常在新的情况下驱动正常运行的产品和系统，这是一个非凡的认知壮举。而且，当您能够设计能够在 100 美元的时间内工作的解决方案时，
*你不应该使用机器学习 *。

幸运的是，对于越来越多的机器学习 (ML) 科学家社区来说，我们想要自动化的许多任务并不容易转变为人类的聪明才智。想象一下，用你所知道的最聪明的头脑围绕白板，但这次你正在解决以下问题之一：

* 编写一个程序，预测明天的天气给定的地理
信息, 卫星图像和过去天气的尾随窗口.
* 编写一个程序，以自由格式文本表示的问题，并正确回答问题。
* 编写一个程序，给出一个图像可以识别它包含的所有人，周围绘制轮廓。
* 编写一个程序，向用户提供他们很可能喜欢但在自然浏览过程中不可能遇到的产品。

在这些情况下，即使是精英程序员也无法从头开始编写解决方案。这种情况的原因可能会有所不同。有时候，我们正在寻找的程序遵循一种随着时间的推移而变化的模式，我们需要我们的程序来适应。在其他情况下，关系（例如像素和抽象类别之间的关系）可能太复杂，需要数千或数百万的计算，这些计算超出了我们的意识（即使我们的眼睛毫不费力地管理任务）。ML 是一项强大的技术研究，可以 * 从 * 体验 * 中学习 *。随着 ML 算法积累了更多的经验，通常采用观测数据或与环境交互的形式，其性能会提高。将这与我们的确定性电子商务平台进行对比，该平台根据相同的业务逻辑执行，无论积累多少经验，直到开发人员自己 * 学习 * 并决定是时候更新软件。在这本书中，我们将教你机器学习的基础知识，并特别关注深度学习，这是一套强大的技术，推动计算机视觉、自然语言处理、医疗保健和基因组学等不同领域的创新。

## 一个激励性的例子

在我们开始写作之前，这本书的作者，像许多劳动力一样，不得不成为咖啡因。我们跳上车，开始驾驶。使用 iPhone，亚历克斯叫出 “嘿 Siri”，唤醒手机的语音识别系统。然后穆指挥 “蓝瓶咖啡店的方向”。手机很快显示了他的命令的转录。它还认识到，我们正在寻求方向，并启动了地图应用程序来满足我们的要求。启动后，地图应用程序会识别多条路线。在每条路线旁边，电话显示预测的运输时间。虽然我们为了教学方便而制作这个故事，但它表明，在短短几秒钟的时间内，我们与智能手机的日常互动可以吸引多种机器学习模型。

想象一下，只需编写一个程序来响应一个 * 唤醒词 *，如 “Alexa”，“好吧，谷歌” 或 “Siri”。如 :numref:`fig_wake_word` 所示，只需要一台计算机和一个代码编辑器就可以自己在一个房间里进行编码。你将如何从第一个原则编写这样的程序？想想一下... 问题很困难每秒钟，麦克风将收集大约 44,000 个样本。每个样本都是声波幅度的测量值。什么规则可以从原始音频片段可靠地映射到有关片段是否包含唤醒字的自信预测 “`{yes, no}`”？如果你被卡住了，不要担心。我们也不知道如何从头开始编写这样的程序。这就是为什么我们使用 ML。

![Identify an awake word.](../img/wake-word.svg)
:label:`fig_wake_word`

这是诀窍。通常情况下，即使我们不知道如何明确地告诉计算机如何从输入到输出的映射，我们仍然能够自己执行认知的壮举。换句话说，即使你不知道
*如何编程计算机 * 识别单词 “Alexa”，
你自己 * 能够 * 识别这个词 “Alexa”。有了这种能力，我们可以收集一个巨大的 * 数据集 *，其中包含音频示例和标签那些 * do* 和 * 不 * 包含唤醒字。在 ML 方法中，我们不尝试设计一个系统
*明确 * 识别唤醒词。
相反，我们定义了一个灵活的程序，其行为由一些 * 参数 * 确定。然后我们使用数据集来确定最好的参数集, 那些提高我们程序的性能相对于某种程序的性能对感兴趣的任务.

你可以把参数视为旋钮，我们可以转动，操纵程序的行为。修复参数，我们称该程序为 * 模型 *。我们可以通过操作参数生成的所有不同程序（输入-输出映射）的集合称为 * 系列 * 模型。使用我们的数据集选择参数的 *meta 程序 * 称为 * 学习算法 *。

在我们继续使用学习算法之前，我们必须精确定义问题，固定输入和输出的确切性质，并选择适当的模型系列。在这种情况下，我们的模型接收一段音频作为 * 输入 *，并在 “`{yes, no}`` 中生成一个选择作为 * 输出 *。如果一切都按计划进行，模型的猜测通常是正确的，即代码片段是否包含唤醒字。

如果我们选择合适的模型系列，那么应该有一个旋钮设置，以便模型每次听到 “Alexa” 这个词时都会触发 '`yes``。由于唤醒词的确切选择是任意的，我们可能需要一个足够丰富的模型家族，以便通过另一个旋钮设置，它只有在听到 “杏” 这个词时才能触发 ``yes``。我们希望同一个模型系列应该适合 * "Alexa" 认可 * 和 * "杏" 认可 *，因为它们看起来，直观地看来是类似的任务。但是，如果我们想处理根本不同的输入或输出，我们可能需要一个完全不同的模型系列，比如说我们是想从图像映射到字幕，或者从英语句子映射到中文句子。

正如你可能猜到的，如果我们只是随机设置所有旋钮，我们的模型不太可能会识别 “Alexa”，“杏” 或任何其他英文单词。在深度学习中，* 学习 * 是我们发现旋钮的正确设置，从而从我们的模型中强制所需行为的过程。

如 :numref:`fig_ml_loop` 所示，培训过程通常如下所示：

1. 从一个无法做任何有用的随机初始化模型开始。
1. 抓取一些已标记的数据（例如，音频片段和相应的 “`{yes, no}`” 标签）
1. 调整旋钮，使模型相对于这些例子吸得更少
1. 重复，直到模型是真棒。

![A typical training process. ](../img/ml-loop.svg)
:label:`fig_ml_loop`

总结一下，而不是编写唤醒词识别器，我们编写了一个程序，可以 * 学习 * 识别唤醒词，
*如果我们提供一个大型标记的数据集 *。
您可以通过将程序与数据集一起呈现为 * 使用数据 * 编程来确定程序的行为。我们可以通过为我们的机器学习系统提供许多猫狗示例来 “编程” 猫探测器，例如下图：

|cat|cat|dog|dog|
|:---------------:|:---------------:|:---------------:|:---------------:|
|![cat3](../img/cat3.jpg)|![](../img/cat2.jpg)|![](../img/dog1.jpg)|![](../img/dog2.jpg)|

这样，探测器最终将学会发出一个非常大的正数，如果它是一只猫，一个非常大的负数，如果它是一只狗，如果它不确定的东西接近零，这几乎没有划伤 ML 可以做什么的表面。

深度学习只是解决机器学习问题的许多流行方法之一。到目前为止，我们只讨论了机器学习，而不是深度学习。要了解深度学习为什么很重要，我们应该暂停一会儿，突出几个关键点。

首先，我们到目前为止讨论的问题 —— 从原始音频信号学习、图像的原始像素值，或任意长度的句子与外语对应的对应方之间的映射 —— 都是深度学习卓越的问题，而传统的 ML 方法被动摇。深度模型是 * 深度 *，正是因为它们学习了许多 * 层 * 的计算。事实证明，这些多层次（或分层）模型能够以以前的工具无法做到的方式处理低层次感知数据。在过去的日子里，将 ML 应用于这些问题的关键部分是提出手动设计的方法，将数据转换为适合 * 浅 * 模型的某种形式。深度学习的一个关键优势是，它不仅取代了传统学习管道末端的 * 浅 * 模型，而且取代了劳动密集型特征工程过程。其次，通过取代大部分 * 特定于域的预处理 *，深度学习消除了以前分离的计算机视觉、语音识别、自然语言处理、医疗信息学和其他应用领域的许多边界，提供了一套统一的工具来解决各种不同的问题问题。

## 关键组件：数据、模型和算法

在我们的 * 唤醒词 * 样本中，我们描述了一个由音频片段和二进制标签组成的数据集，并且我们给出了一个手动波浪感觉，介绍了如何 * 训练 * 一个模型来近似从片段到分类的映射。这种问题，我们试图预测一个指定的未知 * 标签 * 给定已知 * 输入 *，给定一个由示例组成的数据集，其标签被称为 * 监督学习 *，它只是许多 * 种 * 机器学习问题中的一个。在下一节中，我们将深入探讨不同的 ML 问题。首先，无论我们遇到什么样的 ML 问题，我们想更多地了解一些核心组件，这些核心组件将跟随我们：

1. * 数据 *，我们可以从中学习。
2. 如何变换数据的 * 模型 *。
3. 一个 * 丢失 * 函数，用于量化模型的 * 坏处 *。
4. * 算法 * 用于调整模型参数以最小化损失。

### 数据

不用说，如果没有数据，你就无法进行数据科学。我们可能会丢失数百页思考究竟是什么数据，但现在，我们将在实际方面错误，并将重点放在需要关注的关键属性上。一般来说，我们关心的是 * 示例 *（也称为 * 数据点 *、* 样本 * 或 * 实例 *）的集合。为了有效地处理数据，我们通常需要提出一个合适的数值表示。每个 * 示例 * 通常由一组名为 * 要素 * 的数字属性组成。在上述监督学习问题中，一个特殊的特征被指定为预测 * 目标 *, (有时称为 * 标签 * 或 * 相关变量 *)。然后，模型必须进行预测的给定特征可以简单地称为 * 特征 *，（或者通常称为 * 输入 *、* 协变量 * 或 * 独立变量 *）。

如果我们正在处理图像数据，每张单独的照片可能构成一个 * 示例 *，每张照片都由一个与每个像素亮度相对应的有序数值列表表示。$200\times 200$ 彩色照片将包含 $200\times200\times3=120000$ 数值，对应于每个空间位置的红色、绿色和蓝色通道的亮度。在一个更传统的任务中，我们可能会试图预测患者是否会生存，考虑到一组标准的特征，如年龄、生命体征、诊断等。

当每个样本的特征是相同数量的数值时，我们说数据由 * 固定长度 * 向量组成，我们将向量的（常量）长度描述为数据的 * 维度 *。正如你可能想象的那样，固定长度可以是一个方便的属性。如果我们想训练一个模型来识别显微镜图像中的癌症，固定长度的输入均值我们不需要担心的事情。

但是，并非所有数据都可以很容易地表示为固定长度向量。虽然我们可能期望显微镜图像来自标准设备，但我们不能指望从互联网上开采的图像都以相同的分辨率或形状显示。对于图像，我们可能会考虑将它们全部裁剪为标准大小，但该策略只能让我们到目前为止。我们可能会在裁剪出来的部分丢失信息。此外，文本数据更顽固地抵抗固定长度的表示。考虑在亚马逊、IMDB 或 TripAdvisor 等电子商务网站上留下的买家评论。有些是短：“它臭！”.其他人漫步的网页。与传统方法相比，深度学习的一个主要优势是现代模型可以处理 * 变量长度 * 数据的比较优雅。

一般来说，我们拥有的数据越多，我们的工作就越容易。当我们拥有更多的数据时，我们可以训练更强大的模型，并减少对预先设想的假设的依赖。这种制度从（相对）小数据转变为大数据是现代深度学习成功的主要因素。为了推动这一点，许多深度学习中最令人兴奋的模型在没有大型数据集的情况下不起作用。其他一些国家在低数据制度中工作，但没有比传统做法更好。

最后，拥有大量数据并巧妙地处理它是不够的。我们需要 * 右 * 数据。如果数据充满错误，或者选择的功能无法预测目标感兴趣量，则学习将会失败。这种情况很好地被陈词滥调：* 垃圾进入，垃圾出 *。此外，预测性能差并不是唯一的潜在后果。在机器学习的敏感应用中，例如预测性警务、简历筛选和用于贷款的风险模型，我们必须特别警惕垃圾数据的后果。数据集中会出现一种常见故障模式，其中某些人群组在训练数据中未表示。想象一下，在野外应用从未见过黑皮肤的皮肤癌识别系统。如果数据不仅代表某些群体，而且反映了社会偏见，也可能发生失败。样本如，如果使用过去的雇用决策来培训将用于筛选简历的预测模型，那么机器学习模型可能会无意中捕捉和自动化历史不公正现象。请注意，这一切都可能发生在没有数据科学家积极阴谋，甚至不知道的情况下。

### 模型

大多数机器学习在某种意义上涉及 * 转换 * 数据。我们可能希望建立一个系统来收集照片并预测 * 笑脸-ness*。或者，我们可能需要摄取一组传感器读数，并预测读数的 * 正常 * 与 * 异常 *。通过 * 模型 *，我们表示用于摄取一种类型的数据和吐出可能不同类型的预测的计算机制。特别是，我们对可以从数据中估计的统计模型感兴趣。虽然简单的模型完全能够解决适当的简单问题，但我们在这本书中关注的问题却延伸了经典方法的极限。深度学习与经典方法的区别主要是它关注的一系列强大的模型。这些模型包括许多连续的数据转换，这些转换是从上到下链接在一起的，因此名称为 * 深度学习 *。在讨论深度神经网络的过程中，我们将讨论一些更传统的方法。

###  客观职能

早些时候，我们将机器学习引入为 “从经验中学习”。通过在这里学习 *，我们的均值随着时间的推移在某个任务上 * 改进 *。但是，谁能说什么构成改进？您可能会想象我们可以建议更新我们的模型，有些人可能不同意提议的更新是改进还是减少。

为了开发一个正式的学习机器数学系统，我们需要有正式的衡量模型有多好（或坏）。在机器学习和更广泛的优化中，我们称之为这些客观函数。按照惯则，我们通常定义客观函数，以便 * 较低 * 是 * 更好 *。这只是一项公约。您可以采取任何功能 $f$，其中更高更好，并将其变成一个新的函数 $f'$，这是质量相同的，但通过设置 $f' = -f$，较低更好。因为较低越好，所以这些函数有时被称为
*损失函数 * 或 * 成本函数 *。

当试图预测数值时，最常见的目标函数是平方误差 $(y-\hat{y})^2$。对于分类，最常见的目标是最大限度地减少误差率，即我们的预测与真实值不一致的实例部分。一些目标（如平方误差）很容易优化。由于不可分化或其他并发症，其他因素（如误差率）难以直接优化。在这些情况下，通常会优化 * 代理目标 *。

通常，损失函数是根据模型的参数定义的，并取决于数据集。我们模型参数的最佳值是通过最大限度地减少由为训练收集的一些 * 示例 * 组成的 * 训练集 * 造成的损失来学习的。但是，在训练数据上做得很好并不能保证我们在（看不到的）测试数据上做得很好。因此，我们通常希望将可用数据拆分为两个分区：训练数据（用于拟合模型参数）和测试数据（用于评估），报告以下两个数量：

 * ** 训练错误：**
训练模型的数据上的误差。你可以认为这是一个学生在练习考试中的分数，用来准备一些真正的考试。即使结果令人鼓舞，这并不能保证最终考试的成功。
 * ** 测试误差：** 这是在未看到的测试集上发生的错误。
这可能会显著偏离训练误差。当模型在训练数据上表现良好，但未能归纳到未见的数据时，我们说它是 * 覆盖 *。在现实生活中，尽管在实践考试中做得很好，但这就像是在真正的考试中打败。

### 优化算法

一旦我们得到了一些数据源和表示，一个模型和一个明确定义的目标函数，我们需要一个能够搜索最佳参数以最小化损失函数的算法。神经网络最流行的优化算法遵循一种称为梯度下降的方法。简而言之，在每个步骤中，他们都会检查每个参数，如果您只是少量地扰动该参数，训练集损失会如何移动。然后，他们更新参数，以减少损失的方向。

## 机器学习的种类

在以下部分中，我们将更详细地讨论几个 * 类 * 机器学习问题。我们从一个 * 目标 * 的列表开始，即我们希望机器学习做的事情的列表。请注意，目标补充了一组 * 如何 * 实现它们的技术，包括数据类型，模型，培训技术等。下面的列表只是 ML 可以解决的问题的样本，以激励读者，并为我们提供一些共同的语言，当我们谈论更多整个书的问题。

### 受监督的学习

受监督的学习解决了预测 * 目标 * 给定 * 输入 * 的任务。目标，我们通常称之为 * 标签 *，通常用 *y* 表示。输入数据（也称为 * 要素 * 或协变量）通常表示 $\mathbf{x}$。每个（输入，目标）对称为 * 示例 * 或 * 实例 *。有时，当上下文清楚时，我们可以使用术语示例来指输入的集合，即使相应的目标不明。我们表示任何具有下标的特定实例，通常为 $i$，例如 ($\mathbf{x}_i, y_i$)。数据集是一个由 $n$ 个实例组成的集合。我们的目标是生成一个模型 $f_\theta$，该模型将任何输入 $\mathbf{x}_i$ 映射到一个预测值 $f_{\theta}(\mathbf{x}_i)$。

以一个具体的样本为基础，如果我们在医疗保健领域工作，那么我们可能想要预测一个病人是否会发作心脏病。这个观察，* 心脏病发作 * 或 * 没有心脏发作 *，将是我们的标签 $y$。输入数据 $\mathbf{x}$ 可能是生命体征，如心率、舒张压和收缩压等。

监督发挥作用，因为在选择参数 $\theta$ 时，我们（主管）为模型提供了一个由 * 标记样本 *（$\mathbf{x}_i, y_i$）组成的数据集，其中每个示例 $\mathbf{x}_i$ 都与正确的标签匹配。

在概率方面，我们通常对估计条件概率 $P(y|x)$ 感兴趣。虽然这只是机器学习的几个范例之一，但受监督的学习占行业机器学习成功应用的绝大多数。部分原因是，许多重要任务可以被清晰地描述为估计未知事物的概率给定一组特定的可用数据：

* 预测癌症与不是癌症，给出 CT 图像。
* 预测正确的法语翻译，给出了一个英语句子。
* 根据本月的财务报告数据预测下月股价。

即使简单的描述 “从输入预测目标”，监督学习也可以采取许多形式，需要大量的建模决策，这取决于（除其他考虑因素外）的类型、大小以及输入和输出的数量。样本，我们使用不同的模型来处理序列（如文本字符串或时间序列数据）和处理固定长度矢量表示。我们将在本书的前 9 部分深入探讨许多这些问题。

非正式地，学习过程看起来像这样：获取已知协变量的大量示例集合，并从它们中选择一个随机子集，获取每个实例的真实值值标签。有时，这些标签可能是已收集到的可用数据（例如，病人是否在下一年内死亡？）以及其他时候，我们可能需要使用人类注释员来标签数据（例如，将图像分配给类别）。

这些输入和相应的标签共同构成了训练集。我们将训练数据集提供到监督学习算法中，该函数将数据集作为输入并输出另一个函数，* 学习模型 *。最后，我们可以将先前看不到的输入提供给学习模型，使用其输出作为相应标签的预测。整个过程是在 :numref:`fig_supervised_learning` 中绘制的。

![Supervised learning.](../img/supervised-learning.svg)
:label:`fig_supervised_learning`

#### 回归

也许最简单的监督学习任务来缠绕你的头部是 * 回归 *。样本，考虑一组从房屋销售数据库收集的数据。我们可能会构建一个表格，其中每行对应于不同的房子，每列对应于某些相关属性，例如房子的平方英尺、卧室数量、浴室数量以及到镇中心的分钟数（步行）。在此数据集中，每个 * 示例 * 将是一个特定的房子，相应的 * 要素矢量 * 将是表中的一行。

如果你住在纽约或旧金山，并且你不是亚马逊、谷歌、微软或 Facebook 的首席执行官，那么你家的（平方米镜头，卧室数量，浴室数量，步行距离）特征向量可能看起来像：$[100, 0, .5, 60]$。但是，如果你住在匹兹堡，它可能看起来更像是 $[3000, 4, 3, 10]$。这样的功能向量对于大多数经典的机器学习算法至关重要。我们将继续将与任何样本 $i$ 相对应的特征向量表示为 $\mathbf{x}_i$，我们可以将包含所有特征向量的完整表格作为 $X$。

什么使问题成为 * 回归 * 实际上是输出。假设你是在市场上的一个新的家。您可能需要估计房屋的公平市场价值，考虑到这些功能。目标值，即销售价格，是一个 * 实数 *。如果你还记得真实的正式定义你现在可能正在抓你的头了房屋可能永远不会出售一分之一，更不用说以不合理的数字表示的价格。在这样的情况下，当目标实际上是离散的，但是如果四舍五入发生在一个足够精细的尺度上，我们会滥用语言，并继续将我们的输出和目标描述为实值数字。

我们指的是任何个别目标 $y_i$（对应于样本子 $\mathbf{x}_i$）和所有目标 $\mathbf{y}$（对应于所有实例 $X$）。当我们的目标在某个范围内采用任意值时，我们称之为回归问题。我们的目标是生成一个预测与实际目标值接近的模型。我们表示任何实例 $\hat{y}_i$ 的预测目标。不要担心，如果符号是困扰你。我们将在随后的章节中更彻底地解压。

许多实际问题都是详细描述的回归问题。预测用户将分配给电影的评级可以被认为是一个回归问题，如果你在 2009 年设计了一个伟大的算法来实现这一壮举，你可能已经赢得了 [1-million-dollar Netflix prize](https://en.wikipedia.org/wiki/Netflix_Prize)。预测患者住院时间也是一个回归问题。一个很好的经验法则是，任何 * 多少？* 或 * 多少？* 问题应该建议回归。

* “这个手术需要多少小时？”: * 回归 *
* “这张照片里有多少狗？”：* 回归 *。

但是，如果您可以轻松地将您的问题提出为 “这是 _ 吗？”, 那么它很可能, 分类, 一种不同类型的监督问题，我们将在接下来讨论.即使你之前从未使用过机器学习，你也可能已经非正式地解决了回归问题。样本，想象一下，你修理了你的排水渠，而且你的承包商花了 $x_1=3$ 个小时从你的污水管道中清除了水槽。然后她给你发了一个 $y_1 = \$350 美元的账单。现在想象一下，你的朋友聘请了同一个承包商 $x_2 = 2$ 小时，她收到了 $y_2 = \$250$ 的账单。如果有人随后询问您对即将到来的枪械清除发票会有多少期望，您可能会做出一些合理的假设，例如工作时间越长，花费更多的美元。您还可以假定存在一些基本费用，并且承包商随后按小时收费。如果这些假设是真的，那么给出这两个数据点，您已经可以确定承包商的定价结构：\ $100 per hour plus \$50 显示在您的房子里。如果你遵循这么多，那么你已经理解了线性回归背后的高层想法（并且你只是隐式地设计了一个带有偏差项的线性模型）。

在这种情况下，我们可以生成完全匹配承包商价格的参数。有时这是不可能的，例如，如果某些方差归咎于两个特征之外的某些因素。在这些情况下，我们将尝试学习最小化预测值和观测值之间距离的模型。在我们的大多数章节中，我们将重点讨论两个非常常见的损失之一，L1 损失，其中

$$l(y, y') = \sum_i |y_i-y_i'|$$

和最小均值方损失，或 $L_2$ 损失，其中

$$l(y, y') = \sum_i (y_i - y_i')^2.$$

正如我们稍后将看到的那样，$L_2$ 损失对应于我们的数据被高斯噪声损坏的假设，而 $L_1$ 损失对应于来自拉普拉斯分布的噪声假设。

#### 分类

虽然回归模型非常适合解决 * 多少？* 问题，很多问题不舒服地弯曲到这个模板。样本，银行希望将支票扫描添加到其移动应用程序中。这将涉及客户使用智能手机的相机捕捉支票的照片，机器学习模型需要能够自动理解图像中看到的文本。它还需要理解手写案文更加有力。这种系统被称为光学字符识别 (OCR)，它解决的问题类型称为 * 分类 *。它被用于回归的算法集合不同（尽管许多技术将继承）。

在分类中，我们希望我们的模型查看一个特征向量，例如图像中的像素值，然后预测哪个类别（正式称为 *classes*），在一些（离散）选项集中，有一个样本属于。对于手写数字，我们可能有 10 个类，对应于 0 到 9 的数字。最简单的分类形式是当只有两个类时，我们称之为二元分类的问题。样本，我们的数据集 $X$ 可能包含动物的图像，我们的 * 标签 * $Y$ 可能是类 $\mathrm{\{cat, dog\}}$。在回归中，我们寻求一个 * 回归 * 来输出实值 $\hat{y}$，在分类中，我们寻找一个 * 分类器 *，其输出 $\hat{y}$ 是预测的类赋值。

由于我们随着书的技术性越来越强，可能很难优化一个只能输出硬分类赋值的模型，例如 *cat* 或 *dog*。在这些情况下，用概率的语言表达我们的模型通常要容易得多。给出一个样本 $x$，我们的模型为每个标签分配一个概率 $\hat{y}_k$。因为这些是概率，所以它们需要为正数，加起来可达 $1$，因此我们只需要 $K-1$ 数字来分配 $K$ 类别的概率。这很容易看到二元分类。如果有一个 $0.6$（60 美元\ %$）的概率，不公平的硬币出现，则有一个 $0.4$（40 美元\ %$）的概率，它出现反面。回到我们的动物分类样本，分类器可能会看到图像并输出图像为猫 $P(y=\text{cat} \mid x) = 0.9$ 的概率。我们可以通过说分类器是 $90\ %$ 来解释这个数字，确保图像描绘了一只猫。预测类的概率幅度表达了一个不确定性概念。这不是不确定性的唯一概念，我们将在更高级的章节中讨论其他问题。

当我们有两个以上可能的类时，我们称之为问题 * 多类分类 *。常见的例子包括手写字符识别 `[0, 1, 2, 3 ... 9, a, b, c, ...]`。虽然我们通过尝试最小化 $L_1$ 或 $L_2$ 损失函数来解决回归问题，但分类问题的常见损失函数称为交叉熵。

请注意，最有可能的类不一定是您要用于决策的类。假设你发现这个美丽的蘑菇在你的后院如 :numref:`fig_death_cap` 所示。

![Death cap---do not eat!](../img/death_cap.jpg)
:width:`200px`
:label:`fig_death_cap`

现在，假设你建立了一个分类器，并训练它来根据照片预测蘑菇是否有毒。假设我们的毒素检测分类器输出 $P(y=\mathrm{death cap}|\mathrm{image}) = 0.2$。换句话说，分类器是 $80\ %$ 确保我们的蘑菇 * 不是 * 死帽。尽管如此，你必须成为一个傻瓜才能吃它。这是因为美味的晚餐的某些好处是不值得从中死亡的 20 美元\ %$ 的风险。换句话说，* 不确定风险 * 的影响远远超过了收益。我们可以更正式地看待这个问题。基本上，我们需要计算我们产生的预期风险，也就是说，我们需要将结果的概率乘以与其相关的利益（或损害）：

$$L(\mathrm{action}| x) = E_{y \sim p(y| x)}[\mathrm{loss}(\mathrm{action},y)].$$

因此，食用蘑菇所造成的损失 $L$ 是 $L(a=\mathrm{eat}| x) = 0.2 * \infty + 0.8 * 0 = \infty$，而丢弃它的成本用是 $L(a=\mathrm{discard}| x) = 0.2 * 0 + 0.8 * 1 = 0.8$。

我们的谨慎是有道理的：正如任何真菌学家会告诉我们，上述蘑菇实际上是 * 死帽。分类可能比二进制分类、多类甚至多标签分类更加复杂。实例，有一些用于解决层次结构的分类变体。层次结构假定许多类之间存在某些关系。所以并非所有的错误都是平等的-如果我们必须错误，我们宁愿将错误分类为相关类而不是遥远的类。通常，这称为 * 层次分类 *。一个早期的样本是由于 [Linnaeus](https://en.wikipedia.org/wiki/Carl_Linnaeus)，谁组织的动物在一个层次结构。

在动物分类的情况下，它可能不是那么糟糕，但是我们的模型如果它混淆了一个贵宾犬的恐龙，会付出巨大的惩罚。相关的层次结构可能取决于您计划如何使用模型。样本，拨浪鼓蛇和吊袜带蛇可能在系统发育树上很近，但把摇铃乐误认为吊袜带可能是致命的。

#### 标记

一些分类问题不能整齐地融入二进制或多类分类设置中。样本，我们可以训练一个普通的二进制分类器来区分猫和狗。鉴于计算机视觉的当前状态，我们可以通过现成的工具轻松实现这一目标。然而，无论我们的模型多么准确，当分类器遇到不来梅城市音乐家的图像时，我们可能会发现自己陷入困境。

![A cat, a rooster, a dog and a donkey](../img/stackedanimals.jpg)
:width:`300px`

正如你所看到的，图片中有一只猫，还有一只公鸡，一只狗，一只驴和一只鸟，背景有一些树木。根据我们最终想要对模型做什么，将其视为二元分类问题可能没有多大意义。相反，我们可能希望给模型一个选项，即图像描绘了一只猫 * 和 * 狗 * 和 * 驴
*和 * 一只公鸡 * 和 * 一只鸟。

学习预测类的问题
*不相互排斥 * 称为多标签分类。
自动标记问题通常最好地描述为多标签分类问题。想想人们可能会应用于技术博客上的帖子的标签，例如 “机器学习”、“技术”、“小工具”、“编程语言”、“linux”、“云计算”、“AWS”。典型的文章可能会应用 5-10 个标签，因为这些概念是相关的。关于 “云计算” 的帖子可能会提到 “AWS”，关于 “机器学习” 的帖子也可能涉及 “编程语言”。

在处理生物医学文献时，我们也必须处理这种问题，正确标记文章很重要，因为它允许研究人员对文献进行详尽的审查。在国家医学图书馆，许多专业注释员查看了在 PubMed 中编制索引的每篇文章，将其与 Mesh 中的相关术语相关联，这是一个大约 28k 个标签的集合。这是一个耗时的过程，批注者通常会在存档和标记之间滞后一年。在这里可以使用机器学习来提供临时标签，直到每篇文章都可以进行适当的手动审阅。事实上，几年来，生物安全调查组织拥有 [hosted a competition](http://bioasq.org/) 正是这样做的。

#### 搜索和排名

有时，我们不仅想将每个样本分配给存储桶或实际值。在信息检索领域，我们希望对一组项目进行排名。以 Web 搜索为样本，目标不是确定特定页面是否与查询相关，而是确定哪一个搜索结果对特定用户来说最相关 *。我们真的关心相关搜索结果的排序，我们的学习算法需要从更大的集合中生成有序的元素子集。换句话说，如果我们被要求从字母表中生成前 5 个字母，则返回 “`A B C D E`` and `7322936293614` 之间存在差异。即使结果集相同，集合内的顺序也很重要。

这个问题的一个可能的解决方案是首先分配给设置中的每个元素一个相应的相关性得分，然后检索最高评分的元素。[PageRank](https://en.wikipedia.org/wiki/PageRank)，谷歌搜索引擎背后的原始秘密酱是这样一个评分系统的早期样本，但它是特殊的，它确实不依赖于实际查询。在这里，他们依靠一个简单的相关性过滤器来识别相关项目集，然后依靠 PageRank 对包含查询项的结果进行排序。如今，搜索引擎使用机器学习和行为模型来获取依赖于查询的相关性分数。有整个学术会议专门讨论这个问题。

#### 推荐系统
:label:`subsec_recommender_systems`

推荐系统是另一个与搜索和排名有关的问题设置。问题是类似的，因为目标是向用户显示一组相关项目。主要区别在于在推荐系统的背景下强调 * 个性化 * 给特定用户。实例，对于电影推荐，SciFi 粉丝的结果页面和 Peter S卖家喜剧的结果页面可能会有很大差异。类似的问题会出现在其他推荐设置中，例如零售产品、音乐或新闻推荐。

在某些情况下，买家会提供明确的反馈，告知他们对特定商品的喜爱程度（例如，亚马逊、IMDB、GooDreads 等的商品评级和评论）。在其他一些情况下，他们会提供隐含的反馈，例如跳过播放列表上的标题，这可能表示不满，但可能只是表明歌曲在上下文中是不适当的。在最简单的配方中，这些系统经过培训，以估计一些得分 $y_{ij}$，如估计评分或购买概率，给定用户 $u_i$ 和产品 $p_j$。

鉴于这样的模型，那么对于任何给定的用户，我们可以检索分数最大 $y_{ij}$ 的对象集，然后可以推荐给客户。生产系统比较先进，并且在计算此类分数时考虑详细的用户活动和项目特征。:numref:`fig_deeplearning_amazon` 是亚马逊推荐的深度学习书籍样本，基于个性化算法，经过调整，以捕捉作者的偏好。

![Deep learning books recommended by Amazon.](../img/deeplearning_amazon.jpg)
:label:`fig_deeplearning_amazon`

尽管推荐系统具有巨大的经济价值，但天真地建立在预测模型之上，仍然存在一些严重的概念缺陷。首先，我们只观察 * 审查反馈 *。用户优先评分他们感觉强烈的电影：您可能会注意到项目获得了许多 5 星和 1 星评级，但三星评级显然很少。此外，当前的购买习惯往往是目前使用的推荐算法的结果，但学习算法并不总是考虑到这一细节。因此，反馈循环有可能形成，推荐人系统会优先推荐一个项目，然后由于购买量增加），反过来更频繁地推荐一个项目。许多关于如何处理审查、激励和反馈循环的问题都是重要的开放研究问题。

#### 序列学习

到目前为止，我们已经研究了我们有一些固定数量的投入和产出固定数量的输出的问题。之前，我们考虑从一组固定的功能预测房价：平方英尺，卧室数量，浴室数量，步行时间到市中心。我们还讨论了从图像（固定维度）映射到它属于每个固定数量类的预测概率，或者获取用户 ID 和产品 ID，以及预测星级评级。在这些情况下，一旦我们将固定长度的输入提供到模型中以生成输出，模型会立即忘记它刚刚看到的内容。

如果我们的输入真正具有相同的尺寸，并且连续的输入确实没有任何关系，这可能会很好。但是，我们将如何处理视频片段？在这种情况下，每个片段可能由不同数量的帧组成。如果我们考虑到以前或后续帧，我们对每个帧发生了什么情况的猜测可能会更强大。语言也是如此。一个流行的深度学习问题是机器翻译：用某种源语言接收句子并预测其他语言翻译的任务。

这些问题也发生在医学。我们可能需要一个模型来监测重症监护室的患者，如果他们在接下来的 24 小时内的死亡风险超过某个阈值，则发出警报。我们绝对不希望这个模型每小时都丢弃一切关于患者病史的知识，只是根据最近的测量结果进行预测。

这些问题是机器学习最令人兴奋的应用之一，它们是 * 序列学习 * 的实例。它们需要一个模型来摄入输入序列或发出输出序列（或两者都是！）。后一些问题有时被称为 "`seq2seq``seq2seq`" 问题。口头演讲中的文字转录也是一个 “`seq2seq`” 问题。虽然不可能考虑所有类型的序列转换，但有一些特殊情况值得一提：

** 标记和解析 **。这涉及使用属性对文本序列进行注释。
换句话说，投入和产出的数量基本上是相同的。实例，我们可能想知道动词和主题在哪里。或者，我们可能想知道哪些单词是命名的实体。一般来说，目标是根据结构和语法假设对文本进行分解和注释，以获得一些注释。这听起来比实际上更复杂。下面是一个非常简单的样本，用标签来标记表示哪些单词引用命名实体。

```text
Tom has dinner in Washington with Sally.
Ent  -    -    -     Ent      -    Ent
```

** 自动语音识别 **。对于语音识别，输入序列 $x$
是扬声器的录音（如 :numref:`fig_speech` 所示），输出 $y$ 是扬声器所说的文本记录。面临的挑战是，音频帧（声音通常采样为 8kHz 或 16kHz）比文本多得多，也就是说，音频和文本之间没有 1:1 的对应关系，因为数千个样本对应于单个口语单词。这些是 “`seq2seq`” 问题，其中输出比输入短得多。

![`-D-e-e-p- L-ea-r-ni-ng-`](../img/speech.png)
:width:`700px`
:label:`fig_speech`

** 文本转到发言 **。文本转语音 (TTS) 与语音识别相反。
换句话说，输入 $x$ 是文本，输出 $y$ 是一个音频文件。在这种情况下，输出比输入长 *。虽然 *人us* 很容易识别错误的音频文件，但这对计算机来说并不是那么微不足道。

** 机器翻译 **。与语音识别的情况下，其中相应的
输入和输出以相同的顺序（对齐后）发生，在机器翻译中，顺序反转可能是至关重要的。换句话说，当我们仍然将一个序列转换为另一个序列时，输入和输出的数量以及相应数据点的顺序都不会被假定是相同的。请考虑下面的样本说明德国人在句子末尾放置动词的特殊倾向。

```text
German:           Haben Sie sich schon dieses grossartige Lehrwerk angeschaut?
English:          Did you already check out this excellent tutorial?
Wrong alignment:  Did you yourself already this excellent tutorial looked-at?
```

其他学习任务中出现了许多相关问题。实例，确定用户读取网页的顺序是一个二维布局分析问题。对话问题表现出各种额外的复杂问题，其中确定下一步要说什么，需要考虑到真实世界的知识以及长时间距离对话的先前状态。这是一个积极的研究领域。

### 无监督学习

到目前为止，所有示例都与 * 监督学习 * 有关，即我们向模型提供一个包含要素和相应目标值的巨大数据集的情况。你可以认为受监督的学习者有一份非常专业的工作和一个非常肛门的老板。老板站在你的肩膀上，告诉你到底要做什么，在每一种情况下，直到你学会从情况映射到行动。为这样的老板工作听起来很跛脚。另一方面，很容易取悦这个老板。你只是认识到模式尽可能快和模仿他们的行动。

完全相反的方式，对于一个不知道他们想要你做什么的老板来说，这可能是令人沮丧的。但是，如果你打算成为一名数据科学家，你最好习惯它。老板可能只是递给你一个巨大的数据转储，并告诉你 * 用它做一些数据科学！* 这听起来模糊，因为它是。我们称之为这类问题 * 无监督的学习 *，我们可以提出的问题的类型和数量仅受到我们的创造力的限制。我们将在后面的章节中讨论一些无监督的学习技巧。为了激发您的胃口，我们描述了您可能会问的几个问题：

* 我们可以找到少量的原型
准确地总结数据？给出一组照片，我们可以将它们分成风景照片，狗，婴儿，猫，山峰等的照片？同样，给定用户浏览活动的集合，我们可以将它们分组为具有类似行为的用户吗？此问题通常称为 * 群集 *。
* 我们可以找到少量参数
来准确捕获数据的相关属性？球的轨迹通过球的速度、直径和质量进行了很好的描述。裁缝已经开发了少量参数，可以相当准确地描述人体形状，以便装配衣服。这些问题称为 * 子空间估计 * 问题。如果依赖关系是线性的，则称为 * 主成分分析 *。
* 是否有（任意结构化）对象的表示
（即 $\mathbb{R}^n$ 中矢量的空间），以便符号属性可以很好地匹配？这就是所谓的 * 表示学习 *，它被用来描述实体及其关系，如罗马 $-$ 意大利 $+$ 法国 $=$ 巴黎。
* 是否有根本原因的描述
我们观察到的大部分数据？实例如，如果我们拥有关于房价、污染、犯罪、地点、教育、工资等的人口统计数据，我们能否根据经验数据发现它们之间的关系？与 * 因果 * 相关的领域和
*概率图形模型 * 解决了这个问题。
* 非监督学习的另一个重要和令人兴奋的近期发展
是 * 生成式对抗网络 * (GAN) 的出现。这些为我们提供了一种程序性的方式来合成数据，甚至复杂的结构化数据，如图像和音频。基础统计机制是检验真实数据和假数据是否相同。我们将投入一些笔记本电脑给他们。

### 与环境交互

到目前为止，我们还没有讨论数据实际来自哪里，或者当机器学习模型生成输出时 * 发生了什么。这是因为有监督的学习和无监督的学习不能以非常复杂的方式解决这些问题。在任何一种情况下，我们都会提前获取大量数据，然后将模式识别机器设置为运动状态，而无需再次与环境交互。由于所有的学习都是在算法与环境断开连接之后进行的，因此有时称为 * 离线学习 *。对于受监督的学习，该过程看起来像 :numref:`fig_data_collection`。

![Collect data for supervised learning from an environment.](../img/data-collection.svg)
:label:`fig_data_collection`

离线学习的这种简单性有其魅力。好处是我们可以孤立地担心模式识别，而不会分散这些其他问题的注意力。但缺点是，问题的提法是相当有限的。如果你更雄心勃勃，或者如果你长大了阅读阿西莫夫的机器人系列，那么你可能会想象人为智能机器人不仅能够做出预测，而且能够在世界上采取行动。我们想要考虑智能 * 代理 *，而不仅仅是预测 * 模型 *。这意味着我们需要考虑选择 * 操作 *，而不仅仅是作出 * 预测 *。此外，与预测不同，行动实际上会影响环境。如果我们想训练一个智能特工，我们必须考虑它的行为可能影响特工未来的观察。

考虑到与环境的交互关系会打开一整套新的建模问题。环境是否：

* 还记得我们以前做过什么吗？
* 想帮助我们，例如，用户将文本读入语音识别器？
* 想要击败我们，例如垃圾邮件过滤（反垃圾邮件发送者）或玩游戏（对抗对手）？
* 不在乎（因为在许多情况下）？
* 是否正在变化的动态（未来的数据总是像过去一样，还是模式随着时间的推移而改变，无论是自然还是响应我们的自动化工具）？

最后一个问题提出了 * 分配移动 * 的问题，（当训练和测试数据不同时）。这是我们大多数人在参加由讲师撰写的考试时遇到的问题，而家庭作业是由她的 TAS 组成的。我们将简要介绍强化学习和对抗式学习，这两种设置明确考虑与环境相互作用。

### 强化学习

如果您有兴趣使用机器学习来开发与环境交互并采取行动的代理，那么您可能会最终专注于 * 强化学习 * (RL)。这可能包括应用于机器人、对话系统，甚至开发用于视频游戏的 AI。
*深度加强学习 * (DRL)，适用
深度神经网络 RL 问题，已经激增的普及。突破 [deep Q-network that beat humans at Atari games using only the visual input](https://www.wired.com/2015/02/google-ai-plays-atari-like-pros/) 和 [AlphaGo program that dethroned the world champion at the board game Go](https://www.wired.com/2017/05/googles-alphago-trounces-humans-also-gives-boost/) 就是两个突出的例子。

强化学习给出了一个非常普遍的问题说明，在这个问题中，代理通过一系列 * 时间线 * 与环境进行交互。在每次 $t$ 时，代理从环境中收到一些观测值 $o_t$，并且必须选择一个动作 $a_t$，然后通过某种机制（有时称为执行器）传送回环境。最后，代理从环境中获得奖励 $r_t$。然后，代理接收后续观察，并选择后续操作等。RL 代理的行为受 * 策略 * 管辖。简而言之，* 策略 * 只是一个从观测（环境）映射到操作的函数。强化学习的目标是制定一个良好的政策。

![The interaction between reinforcement learning and an environment.](../img/rl-environment.svg)

RL 框架的一般性是难以强调的。样本，我们可以将任何监督学习问题转换为 RL 问题。假设我们有一个分类问题。我们可以创建一个 RL 代理，其中包含一个对应于每个类的 * 操作 *。然后，我们可以创建一个环境，给予的奖励与原始监督问题完全相同的损失函数完全相同。

尽管如此，RL 还可以解决许多监督学习无法解决的问题。样本，在监督学习中，我们总是期望训练输入与正确的标签相关联。但在 RL 中，我们并不认为对于每个观测，环境告诉我们最佳操作。在一般情况下，我们只是得到一些奖励。此外，环境甚至可能不会告诉我们哪些行动导致奖励。

考虑样本国际象棋的游戏。唯一真正的奖励信号出现在比赛结束时，我们要么赢，我们可以分配 1 的奖励，或者当我们输了，我们可以分配-1 的奖励。因此，强化学员必须处理 * 学分分配问题 *：确定哪些行为要归功或归咎于某个结果。同样适用于 10 月 11 日获得晋升的员工。这一晋升可能反映了去年采取的大量精心选择的行动。在未来获得更多促销需要弄清楚导致晋升的过程中采取了哪些行动。

强化学习者也可能需要处理部分观察能力的问题。也就是说，当前观察可能不会告诉你关于当前状态的一切。假设一个清洁机器人发现自己被困在房子里许多相同的壁橱之一。要推测机器人的精确位置（因此状态），可能需要在进入衣柜之前考虑其先前的观测结果。

最后，在任何特定时刻，强化学员可能知道一个好的政策，但可能还有许多其他更好的策略，这些策略是代理从未尝试过的。强化学习者必须不断选择是将当前最好的策略作为策略，还是 * 探索 * 战略空间，可能放弃一些短期回报来换取知识。

#### MDP、土匪和朋友

一般的强化学习问题是一个非常普遍的环境。操作影响后续观察。奖励只观察对应于选择的行动。可以完全或部分观察到环境。一次考虑到所有这些复杂性可能会问太多的研究人员。此外，并非每一个实际问题都表现出这种复杂性。因此，研究人员已经研究了一些
*特殊情况 * 强化学习问题。

当环境得到充分观察时，我们称 RL 问题为 * 马尔科夫决策过程 * (MDP)。当状态不依赖于以前的操作时，我们称这个问题为 * 上下文强盗问题 *。当没有状态，只是一组最初未知的奖励可用的动作，这个问题是经典的 * 多武装强盗问题 *。

## 根

虽然许多深度学习方法都是最近的发明，但人类已经持有分析数据和预测未来几个世纪的愿望。事实上，许多自然科学都有其根源。实例，伯努利分布以 [雅各布·伯努利 (1655-1705)](https://en.wikipedia.org/wiki/Jacob_Bernoulli) 命名，[卡尔·弗里德里希·高斯 (1777-1855)](https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss) 发现了高斯分布。实例，他发明了最小均值方算法，今天仍然用于解决从保险计算到医疗诊断的无数问题。这些工具在自然科学方面产生了一种实验性的方法，实例，欧姆关于电阻器中的电流和电压的定律通过线性模型完美描述。

即使在中世纪，数学家对估计有敏锐的直觉。实例，[雅各布·科贝尔 (1460-1533)] 的几何书 (https://www.maa.org/press/periodicals/convergence/mathematical-treasures-jacob-kobels-geometry) 说明了 16 个成年男脚的平均长度，以获得平均脚长度。

![Estimating the length of a foot](../img/koebel.jpg)
:width:`500px`
:label:`fig_koebel`

:numref:`fig_koebel` 说明了此估计器的工作原理。16 名成年男子在离开教堂时被要求排队。然后，它们的总长度除以 16，以便得出现在 1 英尺的估计值。这种 “算法” 后来得到了改进，以处理脚形不正确的问题 —— 两名最短和最长英尺的男子被送走，平均仅超过剩余部分。这是修剪均值估计的最早示例之一。

随着数据的收集和可用性，统计数据真正起飞。其中一个巨头，[罗纳德·费舍尔（1890-1962）]（https://en.wikipedia.org/wiki/Ronald_Fisher），对其理论及其在遗传学中的应用作出了重大贡献。他的许多算法（如线性判别分析）和公式（如 Fisher 信息矩阵）今天仍然在频繁使用（甚至他在 1936 年发布的虹膜数据集有时仍然被用来说明机器学习算法）。Fisher 也是优生学的支持者，这应该提醒我们，数据科学在道德上可疑的应用与其在工业和自然科学中的生产用途一样长期和持久的历史。

对机器学习的第二个影响来自信息理论 [（克劳德·香农，1916-2001）]（https://en.wikipedia.org/wiki/Claude_Shannon）和 [艾伦·图灵（1912-1954）]（https://en.wikipedia.org/wiki/Alan_Turing）的计算理论。图灵提出了一个问题：“机器能思考吗？”在他著名的论文 [Computing machinery and intelligence](https://en.wikipedia.org/wiki/Computing_Machinery_and_Intelligence)（心灵，1950 年 10 月）。在他所描述的图灵测试中，如果人类评估员难以根据文本交互区分来自机器的回复和人类的回复，那么机器就可以被认为是智能的。

另一种影响可以发现在神经科学和心理学。毕竟，人类清楚地表现出智能行为。因此，问一下是否可以解释并可能对这种能力进行逆向工程是完全合理的。以这种方式启发的最古老的算法之一是由 [唐纳德·赫布（1904-1985 年）]（https://en.wikipedia.org/wiki/Donald_O._Hebb）制定的。在他的开创性著作《行为组织 :cite:`Hebb.Hebb.1949`》中，他假设神经元通过积极的强化学习。这被称为 Hibbian 学习规则。它是 Rosenblatt 感知器学习算法的原型，它为当今深度学习奠定了基础的许多随机梯度下降算法奠定了基础：强化理想行为并减少不良行为，以获得神经网络中参数的良好设置。

生物灵感是什么给 * 神经网络 * 他们的名字。一个多世纪以来（可追溯到亚历山大·贝恩，1873 年和詹姆斯·谢灵顿，1890 年的模型），研究人员试图组装类似于互动神经元网络的计算电路。随着时间的推移，生物学的解释已经变得不那么文字，但名字卡住。在它的核心，谎言可以在当今大多数网络中找到的几个关键原则：

* 线性和非线性处理单元的交替，通常称为 * 层 *。
* 使用链规则（也称为 * 反向传播 *）一次性调整整个网络中的参数。

在初步迅速进展之后，从 1995 年左右到 2005 年，神经网络的研究一直处于衰退状态。这是由于若干原因造成的。培训网络在计算上是非常昂贵的。虽然在上个世纪末，RAM 丰富，但计算能力却很少。其次，数据集相对较小。事实上，费舍尔 1932 年的虹膜数据集是测试算法功效的流行工具。MNIST 以其 60,000 个手写数字被认为是巨大的。

鉴于数据和计算的稀缺，核心方法、决策树和图形模型等强大的统计工具在经验上证明具有优越性。与神经网络不同，它们不需要几周的时间来训练，并提供了可预测的结果，并且具有强有力的理论保证。

## 深度学习之路

由于万维网，为数亿万用户提供服务的公司出现，廉价、高质量的传感器的传播、廉价的数据存储（Kryder 定律）和廉价的计算（摩尔定律），尤其是在形式的 GPU, 最初设计用于计算机游戏.突然，似乎计算不可行的算法和模型变得相关（反之亦然）。这在 :numref:`tab_intro_decade` 中得到了最好的说明。

: 数据集与计算机内存和计算能力

|Decade|Dataset|Memory|Floating Point Calculations per Second|
|:--|:-|:-|:-|
|1970|100 (Iris)|1 KB|100 KF (Intel 8080)|
|1980|1 K (House prices in Boston)|100 KB|1 MF (Intel 80186)|
|1990|10 K (optical character recognition)|10 MB|10 MF (Intel 80486)|
|2000|10 M (web pages)|100 MB|1 GF (Intel Core)|
|2010|10 G (advertising)|1 GB|1 TF (Nvidia C2050)|
|2020|1 T (social network)|100 GB|1 PF (Nvidia DGX-2)|
:label:`tab_intro_decade`

显然，RAM 没有跟上数据增长的步伐。与此同时，计算能力的增长超过了现有数据的增长速度。这意味着统计模型需要提高内存效率（这通常是通过添加非线性实现的），同时由于计算预算的增加，能够花更多时间来优化这些参数。因此，机器学习和统计数据的最佳点从（广义）线性模型和卷积核方法转移到深度网络。这也是深度学习的许多支柱，如多层感知 :cite:`McCulloch.Pitts.1943`、卷积神经网络 :cite:`LeCun.Bottou.Bengio.ea.1998`、长短期记忆 :cite:`Hochreiter.Schmidhuber.1997` 和 Q-学习 :cite:`Watkins.Dayan.1992`，在过去十年中基本上 “重新发现” 的原因之一。相当长的时间.

最近在统计模型、应用和算法方面的进展有时被比喻为寒武纪爆炸：物种进化迅速进展的时刻。事实上，最先进的不仅仅是可用资源的结果，应用于几十年历史的算法。请注意，下面的列表几乎没有划伤的想法，帮助研究人员在过去十年取得巨大进展的表面。

* 新的容量控制方法，例如滴漏 :cite:`Srivastava.Hinton.Krizhevsky.ea.2014`，有助于减轻过拟合的危险。这是通过在整个网络中应用噪声注入 :cite:`Bishop.1995` 来实现的，用随机变量替换权重来实现的。
* 注意机制解决了一个多世纪以来困扰统计数据的第二个问题：如何在不增加可学参数数量的情况下增加系统的记忆和复杂性。:cite:`Bahdanau.Cho.Bengio.2014` 通过使用只能被视为可学习的指针结构找到了一个优雅的解决方案。而不必记住整个句子，例如，对于固定维度表示中的机器翻译，所有需要存储的只是指向翻译过程的中间状态的指针。这样就可以大大提高长句子的准确率，因为模型在开始生成新句子之前不再需要记住整个句子。
* 多阶段设计，例如通过内存网络 (MemNets) :cite:`Sukhbaatar.Weston.Fergus.ea.2015` 和神经程序器-解释器 :cite:`Reed.De-Freitas.2015` 使统计建模者能够描述迭代推理方法。这些工具允许重复修改深度网络的内部状态，从而在一系列推理中执行后续步骤，类似于处理器修改内存以进行计算的方式。
* 另一个重要发展是发明了全球化学信息系统 :cite:`Goodfellow.Pouget-Abadie.Mirza.ea.2014`。传统上，密度估计和生成模型的统计方法侧重于找到正确的概率分布和从中取样的（通常是近似的）算法。因此，这些算法在很大程度上受到了统计模型固有的灵活性的限制。GAN 中的关键创新是用任意算法取代采样器，并具有可差分参数。然后对这些数据进行调整，使判别器（实际上是双样本检验）无法区分假数据和真实数据。通过使用任意算法生成数据的能力，它开辟了密度估计技术。飞跃的斑马 :cite:`Zhu.Park.Isola.ea.2017` 和假名人面孔 :cite:`Karras.Aila.Laine.ea.2017` 的例子都证明了这一进步。即使是业余涂鸦者也可以根据描述场景布局如何看起来像 :cite:`Park.Liu.Wang.ea.2019` 的草图生成逼真的图像。
* 在许多情况下，单个 GPU 不足以处理可用于培训的大量数据。在过去十年中，构建并行分布式训练算法的能力有了显著提高。设计可扩展算法的关键挑战之一是深度学习优化的主力，即随机梯度下降，依赖于相对较小的小批数据进行处理。同时，小批量限制了 GPU 的效率。因此，在小批量大小为（例如，每批 32 个图像）的 1024 GPU 上的培训相当于 32k 图像的聚合小批次。最近的工作，首先是李 :cite:`Li.2017`，随后是 :cite:`You.Gitman.Ginsburg.2017` 和 :cite:`Jia.Song.He.ea.2018`，将测量大小推至 64k 观测值，从而减少了 Imagenet 上 RESNet50 的训练时间少于 7 分钟。为了进行比较，最初的训练时间按天数的顺序进行测量。
* 计算并行化的能力也对强化学习的进展作出了相当重要的贡献，至少在模拟是一种选择的情况下。这导致计算机在 Go、雅达利游戏、星际争霸和物理模拟（例如使用 MuJoco）中实现超人性能方面取得了显著进展。有关如何在 Alpha Go 中实现这一目标的说明，请参阅例如 :cite:`Silver.Huang.Maddison.ea.2016`。简而言之，如果有大量的（状态，行动，奖励）三重元可用，即每当有可能尝试很多东西来了解它们之间的关系时，强化学习效果最好。模拟提供了这样一个渠道。
* 深度学习框架在传播思想方面发挥了至关重要的作用。第一代允许轻松建模的框架包括 [Caffe](https://github.com/BVLC/caffe)、[Torch](https://github.com/torch) 和 [Theano](https://github.com/Theano/Theano)。许多重要论文都是使用这些工具编写的。到目前为止，它们已被 [TensorFlow](https://github.com/tensorflow/tensorflow) 所取代，通常通过其高级别的 API [Keras](https://github.com/keras-team/keras)、[CNTK](https://github.com/Microsoft/CNTK)、[Caffe 2](https://github.com/caffe2/caffe2) 和 [Apache MxNet](https://github.com/apache/incubator-mxnet) 使用。第三代工具，即深度学习的命令性工具，可以说是由 [Chainer](https://github.com/chainer/chainer) 引领的，它使用类似于 Python NumPy 的语法来描述模型。这个想法已被 [PyTorch](https://github.com/pytorch/pytorch)、墨西哥电子网络的 [Gluon API](https://github.com/apache/incubator-mxnet) 和 [Jax](https://github.com/google/jax) 所采用。这是本课程用来教授深度学习的后一组。

系统研究人员构建更好的工具和统计建模人员构建更好的网络之间的分工大大简化了事情。实例，训练一个线性 Logistic 回归模型曾经是一个非平凡的家庭作业问题，值得于 2014 年在卡内基梅隆大学进行机器学习博士学习。现在，这个任务可以用少于 10 行的代码完成，把它牢牢地放在程序员的掌握中。

## 成功案例

人工智能在提供成果方面有着悠久的历史，否则就难以实现。实例，邮件使用光学字符识别进行排序。这些系统已经部署自 90 年代以来（毕竟，这是著名的 MNIST 和 USPS 集的手写数字的来源）。这同样适用于银行存款的阅读支票和申请人的信用评分。自动检查金融交易是否存在欺诈行为。这形成了许多电子商务支付系统的骨干，如 PayPal，Stripe，支付宝，微信，苹果，Visa，万事达卡。国际象棋的计算机程序几十年来一直具有竞争力。机器学习源在互联网上搜索、推荐、个性化和排名。换句话说，人工智能和机器学习普遍存在，尽管往往隐藏在视线之外。

人工智能直到最近才被人们关注，主要是由于解决以前被认为是难以解决的问题。

* 智能助理（如苹果的 Siri、亚马逊的 Alexa 或谷歌的助理）能够以合理的准确率度回答口语问题。这包括微薄的任务，例如打开灯光开关（对残疾人有好处），直至预约理发师和提供电话支持对话框。这可能是人工智能影响我们的生活的最明显迹象。
* 数字助手的一个关键因素是准确识别语音的能力。这种系统的准确率逐渐提高到达到人类等值 :cite:`Xiong.Wu.Alleva.ea.2018` 某些应用程序的地步。
* 同样，对象识别也取得了很大进展。2010 年，在图片中估计物体是一项相当具有挑战性的任务。在 Imagenet 基准上，:cite:`Lin.Lv.Zhu.ea.2010` 实现了前 5 名误差率为 28%。到 2017 年，:cite:`Hu.Shen.Sun.2018` 将此误差率降至 2.25%。同样，在识别鸟类或诊断皮肤癌方面也取得了惊人的成果。
* 游戏曾经是人类智慧的堡垒。从 TDGammon [23] 开始，一个使用时间差异 (TD) 强化学习、算法和计算进度玩双陆棋的程序导致了各种应用的算法。与十五陆棋不同，国际象棋具有更复杂的状态空间和一组动作。深蓝击败加里·卡斯帕罗夫，坎贝尔等人 :cite:`Campbell.Hoane-Jr.Hsu.2002`，使用大规模的并行性，特殊用途的硬件和高效的搜索通过游戏树。Go 是更困难的仍然，由于其巨大的状态空间。AlphaGo 在 2015 年达到了人类平等，使用深度学习和蒙特卡罗树采样结合使用 :cite:`Silver.Huang.Maddison.ea.2016`。扑克的挑战是，国家空间很大，它没有得到充分的观察（我们不知道对手的卡）。天秤座使用高效的结构化策略 :cite:`Brown.Sandholm.2017` 超越了扑克人的表现。这说明了游戏中令人印象深刻的进步以及高级算法在游戏中发挥了至关重要的作用。
* 人工智能进步的另一个迹象是自动驾驶汽车和卡车的出现。虽然尚未实现完全自主权，但在这方面已经取得了很好的进展，特斯拉、NVIDIA 和 Waymo 等公司的运输产品至少能够实现部分自主权。使完全自主变得如此具有挑战性的原因在于，正确的驾驶需要有能力感知、理解和将规则纳入一个系统。目前，深度学习主要用于这些问题的计算机视觉方面。其余部分由工程师严格调整。

同样，上面的列表几乎没有划痕机器学习对实际应用的影响。实例，机器人学、物流学、计算生物学、粒子物理学和天文学最近取得的一些最令人印象深刻的进步，至少在部件学习方面。因此，ML 正在成为工程师和科学家无处不在的工具。

人工智能启示或 AI 奇异性的问题经常在关于 AI 的非技术性文章中提出。担心的是，不知何故，机器学习系统会变得有感情，并独立于程序员（和主人）来决定直接影响人类生计的事情。在某种程度上，人工智能已经立即影响了人类的生计 — 信用性是自动评估的，自动驾驶员主要是导航车辆，决定是否准许保释使用统计数据作为输入。更轻而易举的是，我们可以让 Alexa 打开咖啡机。

幸运的是，我们远远没有一个有感知的 AI 系统，准备操纵其人类的创造者（或烧他们的咖啡）。首先，人工智能系统是以具体、面向目标的方式进行设计、培训和部署的。虽然他们的行为可能会产生一般情报的错觉，但它是规则、启发式和统计模型的组合，构成了设计的基础。其次，目前的 * 人工通用智能 * 工具根本不存在能够改善自己，理解自己，并能够修改，扩展和改进自己的架构，同时试图解决一般任务。

人工智能在我们的日常生活中被如何使用，这是一个更为紧迫的问题。许多由卡车司机和车间助理完成的微型任务可能会而且将会自动化。农场机器人可能会降低有机农业的成本，但它们也将自动化收获作业。工业革命的这一阶段可能对社会大部分人产生深远的后果（卡车司机和店员是许多州最常见的工作）。此外，统计模型如果不谨慎地应用，可能导致种族、性别或年龄偏差，如果自动化以推动作出相应决定，就会引起对程序公正性的合理关切。确保小心使用这些算法是非常重要的。就我们今天所知道的情况而言，这令我们感到更为紧迫的关切，而不是恶意的超级智能破坏人类的潜力。

## 摘要

* 机器学习研究计算机系统如何利用 * 体验 *（通常是数据）来提高特定任务的性能。它结合了来自统计、数据挖掘、人工智能和优化的想法。通常，它被用作实施人工智能解决方案的一种手段。
* 作为机器学习类，代表性学习侧重于如何自动找到表示数据的适当方式。这往往是通过学习变革的进展来实现的。
* 最近在深度学习方面取得的进展大部分是由廉价传感器和互联网规模应用产生的大量数据以及计算方面取得的重大进展而引发的，主要是通过 GPU 进行的。
* 整个系统优化是获得良好性能的关键组成部分。高效的深度学习框架的可用性使得这种框架的设计和实施变得更加容易。

## 练习

1. 您目前正在编写的代码中的哪些部分可以 “学习”，即通过学习和自动确定代码中所做的设计选择来改进？你的代码是否包含启发式设计选择？
1. 您遇到的哪些问题有很多如何解决它们的例子，但没有具体的方法来自动化它们？这些可能是使用深度学习的主要候选人。
1. 将人工智能的发展视为新的工业革命，算法和数据之间的关系是什么？它是否类似于蒸汽机和煤炭（根本区别是什么）？
1. 您还可以在哪里应用端到端培训方法？物理学？工程？计量经济学？

[Discussions](https://discuss.d2l.ai/t/22)
