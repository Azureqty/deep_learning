# 循环神经网络
:label:`chap_rnn`

到目前为止，我们遇到了两种类型的数据：表格数据和图像数据。对于后者，我们利用图像的规律性设计了专门的层。换句话说，如果我们置换了图像中的像素，则很难推断出其内容，而这些内容在模拟电视时代看起来很像测试模式的背景。

最重要的是，到目前为止，我们默示假设我们的数据都是从一些分布中提取的，并且所有的例子都是独立和相同的分布（i.i.d）。不幸的是，对于大多数数据来说，情况并非如此。例如，本段中的词是按顺序编写的，如果随机排列它们，就很难理解其含义。同样，视频的图像帧、对话的音频信号以及网站上的浏览行为都遵循着顺序。因此，可以合理地假设，针对此类数据的设计专门模型将在描述它们的方面做得更好。

另一个问题来自于这样一个事实，我们不仅可能会接收一个序列作为输入，而且可能会期望获得该序列的后续。例如，任务可能是继续系列 $2, 4, 6, 8, 10, \ldots$ 这是相当常见的时间序列分析, 预测股市, 病人的发烧曲线, 或赛车所需的加速度。同样，我们希望拥有可以处理此类数据的模型。

简而言之，虽然 CNNs 可以有效地处理空间信息，但 **循环神经网络** (RNNs) 旨在更好地处理序列化的信息。RNN 引入状态变量来存储过去的信息，并用其与当前的输入共同决定当前的输出。

许多使用循环网络的例子都是基于文本数据的。因此，我们将在本章重点介绍语言模型。在对序列数据进行更正式的审视之后，我们介绍了预处理文本数据的实用技术。接下来，我们将讨论语言模型的基本概念，并将此讨论作为 RNNs 设计的灵感。最后，我们介绍了 RNNs 的梯度计算方法，以探讨在训练此类网络时可能遇到的问题。

```toc
:maxdepth: 2

sequence
text-preprocessing
language-models-and-dataset
rnn
rnn-scratch
rnn-concise
bptt
```
